\sectionquestion{Logistic Regression}

\begin{parts}


% Question 1
\part[2] A medical dataset contains information on patients and whether they are high risk (Yes $\equiv 1$ or No $\equiv 0$). You decide to use binary logistic regression to predict risk based on two features: Weight (kg) and Height (cm). The training dataset consists of 20 patients, not shown. The test dataset contains the following information for 4 patients:
    \begin{center}
        \begin{tabular}{c| cc | c}
            \hline
            Patient & Weight & Height & High Risk?\\
            \hline
            1 & 80 & 170 & 1 \\
            2 & 60 & 180 & 0 \\
            3 & 70 & 120 & 0 \\ 
            4 & 100 & 150 & 1 \\
            \hline
        \end{tabular}
    \end{center}
    
    \textbf{Select all that apply:} After training, the weights are $w_0$ = 0 (intercept term), $w_1$ = 0.2 (Weight term), $w_2$ = -0.1 (Height term). For which of the test patients does the model make an \emph{incorrect} prediction? 
    {%
    \checkboxchar{$\Box$} \checkedchar{$\blacksquare$} % change checkbox style locally
    \begin{checkboxes}
     \choice $i=1$
     \choice $i=2$
     \choice $i=3$
     \choice $i=4$
     \choice None of the above
    \end{checkboxes}
    }
    \begin{soln}
        Points 1 and 3
    \end{soln}
    \begin{qauthor}
        Kushagra Agarwal, Implement logistic regression for binary classification
    \end{qauthor}
            
\part[1] \textbf{Fill in the blank:}  \textit{The decision boundary for binary logistic regression is \underline{\hspace{8em}}.} \textbf{Select one.}
    
    \begin{checkboxes}
        \choice linear
        \choice quadratic
        \choice exponential
        \choice None of the above
    \end{checkboxes}
    
    \begin{soln}
        linear
    \end{soln}
    
    \begin{qauthor}
        Kushagra Agarwal, Prove that the decision boundary of binary logistic regression is linear
    \end{qauthor}

\clearpage
% Question 2
\part Suppose we have a dataset $\Dc = \{ (\xv^{(i)}, y^{(i)}) \}_{i=1}^N$ where each data point $(\xv^{(i)}, y^{(i)})$ is sampled i.i.d. from a probability distribution $p^*(\xv, y)$. 

\begin{subparts}

\subpart[2] \textbf{Select all that apply:} Which of the following objective functions could be maximized or minimized to obtain a value of $\thetav$ for a binary logistic regression model?
    {%
    \checkboxchar{$\Box$} \checkedchar{$\blacksquare$} % change checkbox style locally
    \begin{checkboxes}
     \choice $\prod_{i=1}^N p_{\thetav}(y^{(i)} \mid \xv^{(i)})$
     \choice $\log \prod_{i=1}^N p_{\thetav}(y^{(i)} \mid \xv^{(i)})$
     \choice $-\log \prod_{i=1}^N p_{\thetav}(y^{(i)} \mid \xv^{(i)})$
     \choice $\sum_{i=1}^N \log p_{\thetav}(y^{(i)|} \mid \xv^{(i)})$
     \choice $-\sum_{i=1}^N \log p_{\thetav}(y^{(i)} \mid \xv^{(i)})$
     \choice None of the above
    \end{checkboxes}
    }
    \begin{soln}
    all of the above
    \end{soln}
    \begin{qauthor}
    Matt
    \end{qauthor}

\subpart[2] \textbf{Short Answer:} Neural the Narwhal has a new dataset $\mathcal{D}'$ sampled from a different probability distribution with a single parameter $\theta \in \Rb$. Instead of finding just the value of $\theta$ that maximizes the likelihood of their dataset, Neural decides to find the values of both $\theta$ and of $N'$ (the size of $\mathcal{D}'$) that maximizes its likelihood. Will Neural's plan help them make predictions on unseen data? Briefly justify your answer in 1-2 sentences.
    \fillwithlines{7em}
    \begin{soln} 
        It will not help because $N'$ is not a parameter of the probability distribution. The size of a dataset has no relation to the probability of a specific value being sampled. Moreover, picking the value of $N'$ that maximizes likelihood might lead to overfitting to the noise in the sample.
    \end{soln}
    \begin{qauthor}
        Max, Apply the principle of maximum likelihood estimation (MLE) to learn the parameters
    of a probabilistic model
    \end{qauthor}
    \end{subparts}

\end{parts}