\sectionquestion{S22 TA Questions Go Here!}

\begin{parts}

\part \textbf{Short answer:} Suppose you would like to use a Perceptron to perform multiclass classification. That is, you are given a training set containing labels in $k$ different classes. 

\begin{subparts}
\subpart[2] Explain why the way in which a perceptron makes classifications makes it infeasible for more than 2 classes. 
\begin{tcolorbox}[fit,height=3cm, width=15cm, blank, borderline={1pt}{-2pt}]
\begin{soln}
Predictions are made based on the sign of the dot product of the weights and the point. This does not generalize for more than 2 classes. 
\end{soln}
\end{tcolorbox}

\subpart[2] Briefly propose a scheme to train a perceptron/multiple perceptrons to perform multiclass classification. 

\begin{tcolorbox}[fit,height=3cm, width=15cm, blank, borderline={1pt}{-2pt}]
\begin{soln}
One vs all. Create encoder variables $e_i$ for each class $i$ that are 1 if the point is in class $i$ and 0 if it is in any other class. Then, train $k$ perceptrons, one for each class. The predictions of these perceptrons represent confidence in a prediction, so take the argmax over all perceptrons for the classification. 
\end{soln}
\end{tcolorbox}

\begin{qauthor}
Brendon  (edited by Brynn)
\end{qauthor}
\end{subparts}

\part[2] Understanding the curse of dimensionality and how it relates to KNNs is important.

\begin{subparts} 
\subpart[1]\textbf{True or False:} The KNN algorithm is highly susceptible to overfitting due to the curse of dimensionality.
    \begin{checkboxes}
     \choice True 
     \choice False
    \end{checkboxes}
    \begin{soln}
    True
    \end{soln}
    \begin{qauthor}
    Samiksha Kale, 3.g 
    
    Comment from Brynn: The preamble is a bit of a giveaway here. Is this intentional? "Understanding the curse of dimenstionality and..."
    \end{qauthor}
\subpart[1] \textbf{Short answer:} If you answered True to the question above, explain one way to reduce overfitting. If you answered False to the question above, explain why it is not susceptible to overfitting.
    \fillwithlines{2em}
    \begin{soln}
    One way to reduce overfitting would be dimensionality reduction. Other answers can include feature selection.
    \end{soln}
    \begin{qauthor}
    Samiksha Kale, 3.g
    \end{qauthor}
 \end{subparts}
 
 \part[2] Bias-Variance Tradeoff in KNNs.

\begin{subparts} 
\subpart[1]\textbf{Select one:} Which of the following is true about $k$ regarding bias?
    \begin{checkboxes}
     \choice As $k$ increases, the bias increases.
     \choice As $k$ increases, the bias decreases.
     \choice As $k$ increases, the bias stays the same.
     \choice Can't determine relationship between $k$ and bias
    \end{checkboxes}
    \begin{soln}
    A
    \end{soln}
    \begin{qauthor}
    Samiksha Kale, 3.b 
    
    Comment from Brynn: Will Matt have covered the bias-variance tradeoff by the exam date?
    \end{qauthor}
\subpart[1] \textbf{Select one:} Which of the following is true about $k$ regarding variance?
    \begin{checkboxes}
     \choice As $k$ increases, the variance increases.
     \choice As $k$ increases, the variance decreases.
     \choice As $k$ increases, the variance stays the same.
     \choice Can't determine relationship between $k$ and variance
    \end{checkboxes}
    \begin{soln}
    B
    \end{soln}
    \begin{qauthor}
    Samiksha Kale, 3.b 
    
    Comment from Brynn: Will Matt have covered the bias-variance tradeoff by the exam date?
    \end{qauthor}
 \end{subparts}  

\part[2] \textbf{Select all that apply:} The cost complexity measurement for a decision tree T is given by:
\begin{equation}
    C_\alpha(T) = C(T) + \alpha|T|
\end{equation}
$C_\alpha(T)$ is a loss function we want to minimize. $C(T)$ is training error, $|T|$ is the number of leaf nodes, and $\alpha$ is a hyperparameter. What will happen if the value of $\alpha$ is increased?
    {%
    \checkboxchar{$\Box$} % change checkbox style locally
    \begin{checkboxes}
     \choice Entropy of labels at the leaf nodes may increase. 
     \choice Training error may increase.
     \choice The tree will achieve worse performance on validation set.
     \choice All of the above. 
    \end{checkboxes}
    }
    \begin{soln}
    A,B
    \end{soln}
    \begin{qauthor}
    Yuxin Guo, 2.h
    
    Comment from Brynn: I don't really understand this question. Is this something covered in class? If we kept this in, I think we would need more explanation and constraints. 
    \end{qauthor}



\part[4] For the following statements, fill in the blank with the term that they best describe: Underfitting, Overfitting, or Both.

\begin{subparts} 
    \subpart[1] High accuracy on the training data but poor accuracy on test data. 
    \begin{tcolorbox}[fit,height=1.5cm, width=8cm, blank, borderline={1pt}{-2pt}]
    \end{tcolorbox}
    \begin{soln}
    Overfitting
    \end{soln}
    \begin{qauthor}
    Rita Zhang, 2.f
    \end{qauthor}
    
    \subpart[1] High bias and low variance
    \begin{tcolorbox}[fit,height=1.5cm, width=8cm, blank, borderline={1pt}{-2pt}]
    \end{tcolorbox}
    \begin{soln}
    Underfitting
    \end{soln}
    \begin{qauthor}
    Rita Zhang, 2.f
    
    Comment from Brynn: We have not talked in depth about this yet. It might be a little out of scope. 
    \end{qauthor}
    
    \subpart[1] If occurs in a decision tree, can be fixed by pruning the decision tree
    \begin{tcolorbox}[fit,height=1.5cm, width=8cm, blank, borderline={1pt}{-2pt}]
    \end{tcolorbox}
    \begin{soln}
    Overfitting
    \end{soln}
    \begin{qauthor}
    Rita Zhang, 2.f
    \end{qauthor}
    
    \subpart[1] Shallow (low-depth) decision tree  which fails to make important attribute distinctions within the training data.
    \begin{tcolorbox}[fit,height=1.5cm, width=8cm, blank, borderline={1pt}{-2pt}]
    \end{tcolorbox}
    \begin{soln}
    Underfitting
    \end{soln}
    \begin{qauthor}
    Rita Zhang, 2.f
    \end{qauthor}
\end{subparts}  
   
\part \textbf{Short answer:} In 1-2 sentences, compare the inductive bias of a K-Nearest Neighbor Classifier which uses Manhattan Distance versus a K-Nearest Neighbor Classifier using Euclidean distance.

\begin{tcolorbox}[fit,height=3cm, width=15cm, blank, borderline={1pt}{-2pt}]
\begin{soln}
In using euclidean distance, we assume that the shortest path between two points determines their relative distances. However, when using Manhattan distance, assume that the distance between points is determined incrementally, moving along grid lines.



\end{soln}
\end{tcolorbox}

\begin{qauthor}
Tara

Comment from Brynn: I'm not quite sure about the solution here--it is mostly just defining manhattan and euclidean distance, but maybe we should explain the difference in terms of the data. E.g. comparing feature distances more than general distances. 
\end{qauthor}

    
\part[2] \textbf{Select all that apply:} Decision trees are also known as classification and regression trees (CART), what are the advantages of CART? :

    {%
    \checkboxchar{$\Box$} % change checkbox style locally
    \begin{checkboxes}
     \choice CART is relatively stable comparing to other models because small variations in the data would not result in a completely different tree being generated. 
     \choice CART requires relatively less effort from users for data preparation.
     \choice High nonlinear relationships between independent variables do not affect tree performance.
     \choice None of the above. 
    \end{checkboxes}
    }
    \begin{soln}
    B, C
    \end{soln}
    \begin{qauthor}
    Junhui Li
    
    Comment from Brynn: I feel like these choices are a bit confusing and I am not sure I agree with them. I also am not sure why we are saying CART if we say this is the same as a decision tree. Why not just refer to decision trees? Would maybe remove
    \end{qauthor}
    
    
    
    % Question 3: What are the advantages of Classification and Regression Trees (CART)?
% (A) Decision trees require relatively less effort from users for data preparation
% (B) Nonlinear relationships between parameters do not affect tree performance.
% (C) Both (A) and (B)
% (D) None of these


\part[4] Since it's exam season, Matt now needs to prepare exam questions for the students taking 10-301/601. He wants the questions to be insightful and interesting, but he also wants a certain distribution of points between the topics that have been covered in the first few weeks of the course. This is all great, but MATT IS TOO BUSY! (Have you seen his calendar?!) 
% With back-to-back meetings, and his EA's booking him for the time he set aside for lunch, it is impossible for him to do this. 
Alas, he calls on his TA's to make questions
% . But they're busy too! Understandable, they're students, and they, too, have exams. So he 
and comes up with a strategy. He will pick a set of 4 TA's who will be responsible for making the questions for the exam, and their responsibilities will be distributed among the remaining staff. The TA's will then have to go through past exam papers, and student feed-backs, to learn what kind of questions, and points distribution works best.
Think about the above setting, and answer the following questions:

\begin{enumerate}
    \item (2 points) In the above scenario, what corresponds (analogously) to the hyper-parameters of a model, and what corresponds to the parameters?
    
    \begin{tcolorbox}[fit,height=3cm, width=15cm, blank, borderline={1pt}{-2pt}]
    \begin{soln}
    Hyper-parameters: Set of 4 TA's\\

    Parameters: Points distribution, Types of questions, etc. A bit open ended, but these options suffice.
    \end{soln}
    \end{tcolorbox}
    
    \item (2 points) What, in the above scenario, would corresponds to a training process, and what is the training set?
    \begin{tcolorbox}[fit,height=3cm, width=15cm, blank, borderline={1pt}{-2pt}]
    \begin{soln}
    Training: Going through Past question papers + student feedback.
    Student Feedback can serve as labels.
    \end{soln}
    \end{tcolorbox}
    
\end{enumerate}

    \begin{qauthor}
    Abuzar Khan
    
    Brynn's comment: I like where this is going! But I think it needs some polishing. It maybe needs some clearer constraints?
    \end{qauthor}


\part[2] What are the major differences between using Entropy and  Information Gain as splitting criterion in Decision Trees?

    \begin{tcolorbox}[fit,height=3cm, width=15cm, blank, borderline={1pt}{-2pt}]
    \begin{soln}
    The information gain is the amount of information obtained about a random variable from observing another random variable whereas entropy is related to the randomness in the information being processed and does not require observation of another random variable. 
    \end{soln}
    \end{tcolorbox}
    
    \begin{qauthor}
    Mukund Subramaniam
    \end{qauthor}


 
 
 
 

\end{parts}




    

   