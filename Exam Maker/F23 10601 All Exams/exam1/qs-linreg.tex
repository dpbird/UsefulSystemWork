 \sectionquestion{Regression and Optimization}


 \begin{parts}

\part You are given the following training dataset of four training examples for regression.


\begin{subparts}
    
    \begin{minipage}{0.6\linewidth}
    
    \subpart[2] \textbf{Numerical answer:} What would $k=1$ nearest neighbor regression with Euclidean distance predict for the test point $\xv = [3, 4]^T$?
        \begin{tcolorbox}[fit,height=1cm, width=2cm, blank, borderline={1pt}{-2pt}]
        %solution
        \end{tcolorbox}
        \begin{soln}
        $\hat{y} = -3$
        \end{soln}
        \begin{qauthor}
        Matt
        \end{qauthor}
        
        
    \end{minipage}
    %
    \begin{minipage}{0.3\linewidth}
    %\begin{wrapfigure}{r}{0.3\linewidth}
    \begin{center}
    \emph{Training Dataset:}
    \begin{tabular}{cccc}
         $i$ & $x_1$ & $x_2$ & $y$  \\
         \midrule
         1 & 3 & 2 & -3 \\
         2 & 1 & 3 & -2 \\
         3 & 0 & 1 & -6 \\
         4 & 1 & 0 & -5 
    \end{tabular}
    \end{center}
    %\end{wrapfigure}
    \end{minipage}
        
    \subpart[2] \textbf{Numerical answer:} What would $k=2$ nearest neighbor regression  with Euclidean distance predict for the test point $\xv = [3, 4]^T$? Rather than weighting the two points by distance, assume this model simply averages the outputs of the two nearest neighbors.
        \begin{tcolorbox}[fit,height=1cm, width=2cm, blank, borderline={1pt}{-2pt}]
        %solution
        \end{tcolorbox}
        \begin{soln}
        $\hat{y} = -2.5$
        \end{soln}
        \begin{qauthor}
        Matt
        \end{qauthor}
    
    \subpart[2] \textbf{Numerical answer:} You train a decision tree regressor and it returns a tree with exactly one split on $x_2 \leq 1$ and whose value at each leaf is the average of the training examples accumulated there. What does this regressor predict on the test point $\xv = [3, -1]^T$?
        \begin{tcolorbox}[fit,height=1cm, width=2cm, blank, borderline={1pt}{-2pt}]
        %solution
        \end{tcolorbox}
        \begin{soln}
        $\hat{y} = -5.5$
        \end{soln}
        \begin{qauthor}
        Matt
        \end{qauthor}
    
\end{subparts}

\part[1] \textbf{True or False:} Gradient descent repeatedly takes a step in the direction of the gradient of a function until it arrives at a local minimum.
    \begin{checkboxes}
     \choice True 
     \choice False
    \end{checkboxes}
    \begin{soln}
    False. It takes a step opposite the direction of the gradient.
    \end{soln}
    \begin{qauthor}
    Matt
    \end{qauthor}

\part[2] \textbf{Numerical answer:} Suppose you wish to optimize the function $J(a, b) = \frac{1}{2}(a - 2)^2 + 3b^2 + 2ab$ with gradient descent. It's partial derivatives are:
\begin{align*}
\frac{\partial J(a,b)}{\partial a} = a + 2b - 2 &&
\frac{\partial J(a,b)}{\partial b} = 2a + 6b
\end{align*}

%\begin{subparts}
    % \subpart[2] \textbf{Derivation:} What is the gradient $[ \frac{\partial J(a,b)}{\partial a}, \frac{\partial J(a,b)}{\partial b} ]^T$?
    %     \begin{tcolorbox}[fit,height=2cm, width=15cm, blank, borderline={1pt}{-2pt}]
    %     %solution
    %     \end{tcolorbox}
    %     \begin{soln}
    %     \begin{align*}
    %     \frac{\partial J(a,b)}{\partial a} &= a + 2b - 2 \\
    %     \frac{\partial J(a,b)}{\partial b} &= 2a + 6b
    %     \end{align*}
    %     \end{soln}
    %     \begin{qauthor}
    %     Matt
    %     \end{qauthor}
    
    % REMOVED 
    % \subpart[2] \textbf{Numerical answer:} What is the numerical value of the gradient $[ \frac{\partial J(a,b)}{\partial a}, \frac{\partial J(a,b)}{\partial b} ]^T$ evaluated at the point $[a,b]^T = [3, -2]^T$?
    %     \begin{tcolorbox}[fit,height=1cm, width=5cm, blank, borderline={1pt}{-2pt}]
    %     %solution
    %     \end{tcolorbox}
    %     \begin{soln}
    %     $dJ/da = 3 - 4 - 2 = -3$ \\
    %     $dJ/db = 6 - 12 = -6$ \\
    %     $[-3, -6]$
    %     \end{soln}
    %     \begin{qauthor}
    %     Matt
    %     \end{qauthor}
    
    %\subpart[2] \textbf{Numerical answer:}
    
    You run gradient descent with constant learning rate $\gamma = 1$ starting at the point $[a,b]^T = [3, -2]^T$. After the first step of gradient descent, what are the parameters $[a,b]$?
        
        $a =$ \begin{tcolorbox}[fit,height=1cm, width=2cm, blank, borderline={1pt}{-2pt},nobeforeafter=false]
        %solution
        \end{tcolorbox}
        
        $b =$ \begin{tcolorbox}[fit,height=1cm, width=2cm, blank, borderline={1pt}{-2pt},nobeforeafter=false]
        %solution
        \end{tcolorbox}
        
        \begin{soln}
        $[a,b]^T = [6,4]^T$
        \end{soln}
        \begin{qauthor}
        Matt
        \end{qauthor}
%\end{subparts}

\clearpage

 \part Consider a linear regression model with parameters $\thetav \in \Rb^M$ and training data $\Dc = \{ (\xv^{(i)}, y^{(i)}) \}_{i=1}^N$, where $\xv^{(i)} \in \Rb^M$. Yet, unlike standard linear regression, we only have positive outputs: $y^{(i)} \in \Rb$ such that $y^{(i)} > 0$. The goal of using mean squared error (MSE) is to get the average residual (the distance between the prediction $\hat{y}^{(i)} = \thetav^T\xv^{(i)}$ and the actual output $y^{(i)}$) as close to 0 as possible. Instead, suppose our goal is to get the average ratio ($\hat{y}^{(i)}$/$y^{(i)}$) as close to 1 as possible by using the following example-specific objective function:
    $$ J^{(i)}(\thetav) = \frac{1}{2}\left(\frac{\thetav^T\xv^{(i)}}{y^{(i)}} - 1\right)^2 $$
    
    \begin{subparts}
    
    \subpart[2] \textbf{Derivation:} What is the partial derivative of this example-specific objective function with respect to the parameter $\theta_m$, that is $\frac{\partial J^{(i)}(\thetav)}{\partial \theta_m}$?
    \begin{tcolorbox}[fit,height=4cm, width=15cm, blank, borderline={1pt}{-2pt}]
    %solution
    \end{tcolorbox}
    \begin{soln}
        $$\frac{\partial J^{(i)}(\thetav)}{\partial \theta_m} = \frac{x_m^{(i)}}{y^{(i)}} \left(\frac{\thetav^T\xv^{(i)}}{y^{(i)}} - 1\right)$$
    \end{soln}

    \subpart[2] \textbf{Derivation:} What is the gradient of this example-specific objective function with respect to the parameters $\thetav$, $\nabla_{\thetav}J^{(i)}(\thetav)$? {\tiny (We will not give consistency points here.)}
    \begin{tcolorbox}[fit,height=4cm, width=15cm, blank, borderline={1pt}{-2pt}]
    %solution
    \end{tcolorbox}
    \begin{soln}
        The gradient of the objective function is
        $$\nabla_{\thetav}J^{(i)}(\thetav) = \frac{\xv^{(i)}}{y^{(i)}} \left(\frac{\thetav^T\xv^{(i)}}{y^{(i)}} - 1\right)$$
    \end{soln}
    
    
    \subpart[2] \textbf{Short answer:} In 1 concise sentence, describe one reason why this would be a bad objective function to use with gradient descent.
    \fillwithlines{6em}
    \begin{soln}
    - When $y^{(i)}\ll x^{(i)}$ or $y^{(i)}\ll \theta^Tx^{(i)}$, the weight update will be extremely large, so the model might overshoot.\\
    - When $y^{(i)}\gg x^{(i)}$, the weight update will be extremely small, so the model will not learn much.\\
    - The model will not update if $x^{(i)}=0$.\\
    \end{soln}
    \begin{qauthor}
        Author: Brandon Wang
        Objective: Implement learning for Linear Regression using ONE optimization technique: (2) gradient descent.
        
        Edited by Henry: another great question, restructured into two subparts (potentially problematic dependency) and reduced number of reasons from 2 to 1. 
    \end{qauthor}

    \subpart[1] \textbf{Numerical answer:} Suppose after training the model for some time, your parameters are $\thetav = [-5, 4, -3, 2, -1]^T$. What is the model's prediction $\hat{y}$ on the test example $\xv = [1, 0, 1, 1, 0]^T$?
    \begin{tcolorbox}[fit,height=1cm, width=2cm, blank, borderline={1pt}{-2pt}]
    %solution
    \end{tcolorbox}
    \begin{soln}
    $$\hat{y} = \thetav^T\xv = - 5 - 3 + 2 = -6$$
    \end{soln}
    \begin{qauthor}
    Matt
    \end{qauthor}
    
    \end{subparts}
    

\end{parts}