\sectionquestion{Recommender Systems}

\begin{parts}


\part Suppose we train a matrix factorization model for estimating the quality score that user $i$ gave to item $j$. We learn the $i$th user factor as $\uv_i$ and the $j$th item factor as $\vv_j$. Our training data consists of the true quality scores $R_{i,j}$ and $R_{i,j} \in \{-2, -1, 0, +1, +2\}$ are integers, where higher is better. Assume the set $\Zc$ consists of pairs $(i,j)$ for which we know the true quality score $R_{i,j}$.
%


\begin{subparts}

\subpart[1] \textbf{Short answer:} Write an expression for the model's prediction of user $i=7$'s quality score for item $j=9$.
    \begin{tcolorbox}[fit,height=2cm, width=6cm, blank, borderline={1pt}{-2pt}]
    %solution
    \end{tcolorbox}
    \begin{soln}
    $\hat{r}_{7,9} = \uv_7^T \vv_9 = \uv_7 \cdot \vv_9$
    \end{soln}
    \begin{qauthor}
    Matt
    \end{qauthor}

\uplevel{
Neural the Narwhal notices that the model's predictions might not be integers. So instead of having real-valued factors, i.e. $\uv \in \Rb^{m,k}, \vv \in \Rb^{n,k}$, he writes a new optimization problem in which they are constrained to be integers, i.e. $\uv \in \Zb^{m,k}, \vv \in \Zb^{n,k}$:
\begin{align*}
    \hat{\uv}, \hat{\vv} = \argmin_{\uv \in \Zb^{m,k}, \vv \in \Zb^{n,k}} J(\uv, \vv)
\end{align*}
where $J(\uv, \vv)$ is the standard squared error objective function used by unconstrained matrix factorization.
}

\subpart[1] \textbf{Select one:} If Neural can solve this optimization problem, will the predicted ratings of the learned model always be integer?
    \begin{checkboxes}
     \choice Yes
     \choice No
    \end{checkboxes}
    \begin{soln}
    Yes
    \end{soln}
    \begin{qauthor}
    Matt
    \end{qauthor}

\subpart[1] \textbf{Short answer:} Neural runs into trouble when trying to solve this optimization problem with gradient descent. What goes wrong?
    \fillwithlines{8em}
    \begin{soln}
    Gradient descent is an unconstrained optimization algorithm, but the new problem is a constrained optimization problem.
    \end{soln}
    \begin{qauthor}
    Matt
    \end{qauthor}

\end{subparts}

\clearpage
\part[2] \textbf{Short answer:} Describe one reason to favor a latent factor method (e.g. matrix factorization) over a neighborhood method when designing a recommender system.
    \fillwithlines{10em}
    \begin{soln}
    - Dimensionality reduction

    - More computationally efficient for **large data**
    
    - Ability to predict for items without ratings
    \end{soln}
    \begin{qauthor}
    Matt
    \end{qauthor}


\end{parts}