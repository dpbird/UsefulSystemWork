\sectionquestion{Working with Data}

\begin{parts}

\part[2] \textbf{Select all that apply:} Suppose you want to predict whether or not Henry will run some ridiculous, over-the-top demonstration in lecture on any given day. Which of the following models could you use for this task? 
    {%
    \checkboxchar{$\Box$} \checkedchar{$\blacksquare$} % change checkbox style locally
    \begin{checkboxes}
        \choice Decision trees
        \choice $k$-NNs
        \choice Perceptrons
        \choice Linear regressors
        \choice None of the above
    \end{checkboxes}
    }
    \begin{soln}
        A, B, C. The task is a classification task so we cannot use linear regression. 
    \end{soln}
    \begin{qauthor}
        Henry
    \end{qauthor}
    
\part[2] \textbf{Select one:} When we train machine learning models, why do we try to minimize the training error instead of directly minimizing the true error?
    \begin{checkboxes}
     \choice It is possible to compute the true error, but it is very computationally expensive, so we use the training error instead.
     \choice Because given a reasonably large training dataset, training error and true error are exactly the same thing.
     \choice Determining the true error requires you to have access to every single possible input and output to the model.
     \choice Using the training error instead of the true error guarantees that your learning algorithm will converge.
    \end{checkboxes}
    \begin{soln}
    C. You cannot calculate the true error, since you need to have access to every single point in the domain to do so (and also an accurate error metric). 
    \end{soln}
    \begin{qauthor}
    Rohan Chawla, Explain the difference between true error and training error.

    Lightly edited by Henry
    \end{qauthor}

\part[2] \textbf{Short answer:} Imagine that the hypothetical instructors of a hypothetical course have hypothetically decided to train a machine learning model to predict a student's final grade. To do so, they gather data from their current cohort of TAs, who all did excellently in previous offerings of \cancel{10-301/601} this hypothetical course. 

In 1-2 concise sentences, describe the primary issue that may occur when using only TA data to train such a model. 
\fillwithlines{9em}
\begin{soln}
    The dataset only contains information about students with good grades so the model may not be able to learn about (or even output) low grades. 
\end{soln}
\begin{qauthor}
    Henry
\end{qauthor}

\begin{comment}
\part Neural wants to train an ML model on a dataset $\mathcal{D}$, but he accidentally duplicates a subset of the training points in $\mathcal{D}$, giving rise to a new dataset, $\mathcal{D}'$! (Assume for $k$-NN that distance ties are broken by majority vote, and that for $k$-NN and decision trees majority vote ties are broken by returning a constant value.)

\begin{subparts}
    \subpart[2] \textbf{Select all that apply:} If Neural duplicates \textit{all} the points on the dataset, which of these models could possibly differ when trained on $\mathcal{D}'$ instead of on $\mathcal{D}$?
    {%
    \checkboxchar{$\Box$} \checkedchar{$\blacksquare$} % change checkbox style locally
    \begin{checkboxes}
        \choice $k$-NN for classification with $k=1$
        \choice Linear regression
        \choice $k$-NN for classification with $k=3$
        \choice Decision tree for classification
        \choice None of the above
    \end{checkboxes}
    
    \begin{soln}
        C.
    \end{soln}
    
    \subpart[2] \textbf{Select all that apply:} If Neural duplicates \textit{only some but not all} (i.e. a \emph{proper} subset) of the points on the dataset, which of these models could possibly differ when trained on $\mathcal{D}'$ instead of $\mathcal{D}$?
    
    \begin{checkboxes}
        \choice k-NN for classification with $k=1$
        \choice Linear regression
        \choice k-NN for classification with $k=3$
        \choice Decision tree for classification
        \choice None of the above
    \end{checkboxes}
    }
    \begin{soln}
        B, C, D.
    \end{soln}
\end{subparts}
\begin{qauthor}
    Chu. Decision trees, k-NN, linear regression. Objectives: Describe a dataset as points in a high dimensional space, and compare models.
\end{qauthor}

\begin{qtester}
EA Feedback: I like this question
\end{qtester}


\part[2] \textbf{Select all that apply:} Neural wants to predict if a student will show up to class given the student's distance from campus and the weather (sunny or rainy). Neural doesn't know which model to use. Which of the following statements are correct?
    {%
    \checkboxchar{$\Box$} \checkedchar{$\blacksquare$} % change checkbox style locally
    \begin{checkboxes}
        \choice Using a decision tree would not be applicable because decision trees cannot work with real-valued features.
        \choice We can use a $1$-NN model for this task but only if we use the Euclidean distance metric.
        %\choice Since linear regression models predict the label of a point based on real-valued features, Neural could use a linear regression model for this task.
        \choice Using a perceptron model here would be reasonable because perceptrons cannot overfit and therefore are suitable for tasks with a small number of data points.
        \choice None of the above
    \end{checkboxes}
    }
\begin{soln}
D.
\end{soln}
\begin{qauthor}
Chu. Decision trees, logistic regression, and perceptron. Identifying inductive biases of ML models.

Edited by Henry: added option B
\end{qauthor}

\begin{qtester}
EA Feedback: I like this question-- I wonder if we want to be even more specific in the options. I am trying to think of edge cases that students could argue... Or we could add a "Justify" option.
\end{qtester}
\end{comment}

\end{parts}